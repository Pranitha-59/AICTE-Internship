{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/nlxp4xD4NLiObVa1gSIR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pranitha-59/AICTE-Internship/blob/main/FINAL_%20PROJECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWUHZq7Txgp2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Rescaling, GlobalAveragePooling2D, Dropout, Dense\n",
        "from tensorflow.keras.applications import EfficientNetV2B2\n",
        "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
        "from tensorflow.keras import callbacks\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "\n",
        "zip_filename = next((name for name in uploaded if name.endswith('.zip')), None)\n",
        "\n",
        "if zip_filename is None:\n",
        "    raise FileNotFoundError(\"Please upload a ZIP file containing the dataset.\")\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/\")\n",
        "\n",
        "\n",
        "extracted_dir = None\n",
        "for root, dirs, files in os.walk(\"/content/\"):\n",
        "    for dir_name in dirs:\n",
        "        if \"TrashType\" in dir_name:  # match partially in case of minor name mismatch\n",
        "            extracted_dir = os.path.join(root, dir_name)\n",
        "            break\n",
        "    if extracted_dir:\n",
        "        break\n",
        "\n",
        "if not extracted_dir or not tf.io.gfile.exists(extracted_dir):\n",
        "    raise FileNotFoundError(\"Could not locate the extracted dataset directory.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9izH_lEnxhfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (260, 260)\n",
        "batch_size = 32\n",
        "seed = 42\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    extracted_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=seed,\n",
        "    shuffle=True,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    extracted_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=seed,\n",
        "    shuffle=True,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(\"âœ… Dataset loaded with classes:\", class_names)\n",
        "\n"
      ],
      "metadata": {
        "id": "yaVDl7N6xhdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
        "\n",
        "def preprocess(image, label):\n",
        "    return preprocess_input(image), label\n",
        "\n",
        "train_ds = train_ds.map(preprocess)\n",
        "val_ds = val_ds.map(preprocess)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "fIoTFQ5wxha3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "M1qU1HmPxhYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autotune = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(autotune)\n",
        "val_ds = val_ds.cache().prefetch(autotune)\n",
        "\n",
        "def preprocess(image, label):\n",
        "    return preprocess_input(image), label\n",
        "\n",
        "train_ds = train_ds.map(preprocess)\n",
        "val_ds = val_ds.map(preprocess)\n",
        ""
      ],
      "metadata": {
        "id": "jwRgmyENxhVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = EfficientNetV2B2(include_top=False, input_shape=(260, 260, 3), weights=\"imagenet\")\n",
        "base_model.trainable = False\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(len(class_names), activation='softmax')\n",
        "])\n",
        ""
      ],
      "metadata": {
        "id": "x3JzhlA_xhS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=5\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mqmzgdoUx-zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"efficientnet_garbage_classifier.keras\")\n",
        "with open(\"class_names.json\", \"w\") as f:\n",
        "    json.dump(class_names, f)\n",
        "\n"
      ],
      "metadata": {
        "id": "2MYJf3JXx-wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W_beaGCux-uA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_batches = tf.data.experimental.cardinality(val_ds)\n",
        "test_ds = val_ds.take(val_batches // 2)\n",
        "val_ds = val_ds.skip(val_batches // 2)\n",
        "test_ds = test_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "model.evaluate(test_ds)\n",
        ""
      ],
      "metadata": {
        "id": "que1Tzhox-rG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true, y_pred = [], []\n",
        "for images, labels in test_ds:\n",
        "    preds = model.predict(images)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend(np.argmax(preds, axis=1))\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "T_PhpQpWySM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from PIL import Image\n",
        "\n",
        "def predict(img):\n",
        "    img = img.resize((260, 260))\n",
        "    img = np.array(img)\n",
        "    img = preprocess_input(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    preds = model.predict(img)\n",
        "    return {class_names[i]: float(preds[0][i]) for i in range(len(class_names))}\n",
        "\n",
        "gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=gr.Label(num_top_classes=3),\n",
        "    title=\"Garbage Classifier\",\n",
        "    description=\"Upload an image of waste to classify it as paper, plastic, metal, etc.\"\n",
        ").launch()\n",
        ""
      ],
      "metadata": {
        "id": "2OALeGGzySJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NLRLzvzBySHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zDESQD-IySEu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}